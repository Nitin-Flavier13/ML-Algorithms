{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Trips & Travel.Com\" company wants to enable and establish a viable business model to expand the customer base. One of the ways to expand the customer base is to introduce a new offering of packages. Currently, there are 5 types of packages the company is offering - Basic, Standard, Deluxe, Super Deluxe, King. Looking at the data of the last year, we observed that 18% of the customers purchased the packages. However, the marketing cost was quite high because customers were contacted at random without looking at the available information. The company is now planning to launch a new product i.e. Wellness Tourism Package. Wellness Tourism is defined as Travel that allows the traveler to maintain, enhance or kick-start a healthy lifestyle, and support or increase one's sense of well-being. However, this time company wants to harness the available data of existing and potential customers to make the marketing expenditure more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks to Solve :  \n",
    "To predict which customer is more likely to purchase the newly introduced travel package  \n",
    "Which variables are most significant.  \n",
    "Which segment of customers should be targeted more.\n",
    "\n",
    "More information:  \n",
    "https://www.kaggle.com/datasets/susant4learning/holiday-package-purchase-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>Visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0          1  41.0     Self Enquiry         3              6.0   \n",
       "1          0  49.0  Company Invited         1             14.0   \n",
       "2          1  37.0     Self Enquiry         1              8.0   \n",
       "3          0  33.0  Company Invited         1              9.0   \n",
       "4          0  36.0     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfFollowups ProductPitched  \\\n",
       "0        Salaried  Female                3.0         Deluxe   \n",
       "1        Salaried    Male                4.0         Deluxe   \n",
       "2     Free Lancer    Male                4.0          Basic   \n",
       "3        Salaried  Female                3.0          Basic   \n",
       "4  Small Business    Male                3.0          Basic   \n",
       "\n",
       "   PreferredPropertyStar MaritalStatus  NumberOfTrips  Passport  \\\n",
       "0                    3.0     Unmarried            1.0         1   \n",
       "1                    4.0      Divorced            2.0         0   \n",
       "2                    3.0     Unmarried            7.0         1   \n",
       "3                    3.0      Divorced            2.0         1   \n",
       "4                    4.0      Divorced            1.0         0   \n",
       "\n",
       "   PitchSatisfactionScore  OwnCar Designation  MonthlyIncome  Visitors  \n",
       "0                       2       1     Manager        20993.0       3.0  \n",
       "1                       3       1     Manager        20130.0       5.0  \n",
       "2                       3       0   Executive        17090.0       3.0  \n",
       "3                       5       1   Executive        17909.0       3.0  \n",
       "4                       5       1   Executive        18468.0       2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Nitin Flavier\\Desktop\\Data Nexus\\Data Science\\ML_BootCamp\\ML_Algos\\Boosting\\Dataset\\Cleaned_Data_Travel.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['ProdTaken'],axis=1)\n",
    "y = df['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProdTaken\n",
       "0    3968\n",
       "1     920\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Column Transformer to Tranform all features under one go\n",
    "cat_feature = X.select_dtypes(include='object').columns\n",
    "num_feature = X.select_dtypes(exclude='object').columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler \n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "# Usually we dont need StandardScaler for DT (random forest or Boosting ensemble techniques)\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "pre_processor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\",oh_transformer,cat_feature),\n",
    "        (\"StandardScaler\",numeric_transformer,num_feature)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pre_processor.fit_transform(X_train) \n",
    "X_test = pre_processor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble means group (here a group of DT are working to predict/classify)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, roc_auc_score, precision_score, recall_score\n",
    "\n",
    "models = {\n",
    "    \"Logistic_Regression\": LogisticRegression(),\n",
    "    \"Decision_Tree\": DecisionTreeClassifier(),\n",
    "    \"Random_Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"GradientBoost Classifier\": GradientBoostingClassifier(),\n",
    "    \"XgBoost Classifier\": XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic_Regression\n",
      "Model Performance for Training set\n",
      "- Accuracy: 0.8445\n",
      "- F1-Score: 0.3830\n",
      "- Precision: 0.6991\n",
      "- Recall: 0.2638\n",
      "- Roc Auc Score: 0.6192\n",
      "\n",
      "Model Performance for Test set\n",
      "- Accuracy: 0.8377\n",
      "- F1-Score: 0.4018\n",
      "- Precision: 0.7521\n",
      "- Recall: 0.2741\n",
      "- Roc Auc Score: 0.6259\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Model: Decision_Tree\n",
      "Model Performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1-Score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "\n",
      "Model Performance for Test set\n",
      "- Accuracy: 0.9089\n",
      "- F1-Score: 0.7714\n",
      "- Precision: 0.7702\n",
      "- Recall: 0.7726\n",
      "- Roc Auc Score: 0.8577\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Model: Random_Forest\n",
      "Model Performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1-Score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "\n",
      "Model Performance for Test set\n",
      "- Accuracy: 0.9120\n",
      "- F1-Score: 0.7269\n",
      "- Precision: 0.9497\n",
      "- Recall: 0.5888\n",
      "- Roc Auc Score: 0.7905\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Model: AdaBoost Classifier\n",
      "Model Performance for Training set\n",
      "- Accuracy: 0.8607\n",
      "- F1-Score: 0.4771\n",
      "- Precision: 0.7619\n",
      "- Recall: 0.3472\n",
      "- Roc Auc Score: 0.6615\n",
      "\n",
      "Model Performance for Test set\n",
      "- Accuracy: 0.8482\n",
      "- F1-Score: 0.4754\n",
      "- Precision: 0.7603\n",
      "- Recall: 0.3458\n",
      "- Roc Auc Score: 0.6594\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Model: GradientBoost Classifier\n",
      "Model Performance for Training set\n",
      "- Accuracy: 0.8842\n",
      "- F1-Score: 0.5876\n",
      "- Precision: 0.8438\n",
      "- Recall: 0.4508\n",
      "- Roc Auc Score: 0.7160\n",
      "\n",
      "Model Performance for Test set\n",
      "- Accuracy: 0.8699\n",
      "- F1-Score: 0.5749\n",
      "- Precision: 0.8208\n",
      "- Recall: 0.4424\n",
      "- Roc Auc Score: 0.7092\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Model: XgBoost Classifier\n",
      "Model Performance for Training set\n",
      "- Accuracy: 0.9997\n",
      "- F1-Score: 0.9992\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9983\n",
      "- Roc Auc Score: 0.9992\n",
      "\n",
      "Model Performance for Test set\n",
      "- Accuracy: 0.9275\n",
      "- F1-Score: 0.7929\n",
      "- Precision: 0.9180\n",
      "- Recall: 0.6978\n",
      "- Roc Auc Score: 0.8412\n",
      "-----------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n = len(models)\n",
    "\n",
    "for key,value in models.items():\n",
    "    model = value \n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    # make predictions \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Trained Data performance \n",
    "    model_train_acc = accuracy_score(y_train,y_train_pred)\n",
    "    model_train_f1 = f1_score(y_train,y_train_pred)\n",
    "    model_train_precision = precision_score(y_train,y_train_pred)\n",
    "    model_train_recall = recall_score(y_train,y_train_pred)\n",
    "    model_train_rocauc_score = roc_auc_score(y_train,y_train_pred)\n",
    "\n",
    "    # Test Data performance \n",
    "    model_test_acc = accuracy_score(y_test,y_test_pred)\n",
    "    model_test_f1 = f1_score(y_test,y_test_pred)\n",
    "    model_test_precision = precision_score(y_test,y_test_pred)\n",
    "    model_test_recall = recall_score(y_test,y_test_pred)\n",
    "    model_test_rocauc_score = roc_auc_score(y_test,y_test_pred)\n",
    "\n",
    "    print(f\"Model: {key}\")\n",
    "\n",
    "    print(\"Model Performance for Training set\")\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_acc))\n",
    "    print(\"- F1-Score: {:.4f}\".format(model_train_f1))\n",
    "    print(\"- Precision: {:.4f}\".format(model_train_precision))\n",
    "    print(\"- Recall: {:.4f}\".format(model_train_recall))\n",
    "    print(\"- Roc Auc Score: {:.4f}\".format(model_train_rocauc_score))\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Model Performance for Test set\")\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_test_acc))\n",
    "    print(\"- F1-Score: {:.4f}\".format(model_test_f1))\n",
    "    print(\"- Precision: {:.4f}\".format(model_test_precision))\n",
    "    print(\"- Recall: {:.4f}\".format(model_test_recall))\n",
    "    print(\"- Roc Auc Score: {:.4f}\".format(model_test_rocauc_score))\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameter tuning\n",
    "rf_params = {\n",
    "    'max_depth': [5,8,10,15,None],\n",
    "    'max_features': [5,7,8,\"auto\"],\n",
    "    \"min_samples_split\": [2,8,15,20],\n",
    "    \"n_estimators\": [100,200,500,1000]\n",
    "}\n",
    "\n",
    "adaboost_params = {\n",
    "    'n_estimators': [50,60,70,80,90],\n",
    "    'algorithm': ['SAMME','SAMME.R'],\n",
    "}\n",
    "\n",
    "gradientboost_params = {\n",
    "    \"loss\": ['log_loss','deviance','exponential'],\n",
    "    \"criterion\": ['friedman_mse','squared_error','mse'],\n",
    "    \"min_samples_split\": [2,8,15,20],\n",
    "    \"n_estimators\": [100,200,500,1000],\n",
    "    \"max_depth\": [5,8,15,None,10]\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "    \"learning_rate\": [0.1,0.01],\n",
    "    \"max_depth\": [5,8,15,None,10],\n",
    "    \"n_estimators\": [100,200,300],\n",
    "    \"colsample_bytree\": [0.5,0.8,1,0.3,0.4]\n",
    "}\n",
    "\n",
    "# models list for hyper-parameter tuning\n",
    "random_cv_models = [\n",
    "    (\"RF\",RandomForestClassifier(),rf_params),\n",
    "    (\"AdaBoostClassifier\",AdaBoostClassifier(),adaboost_params),\n",
    "    (\"GradientBoostClassifier\",GradientBoostingClassifier(),gradientboost_params),\n",
    "    (\"XgBoostClassifier\",XGBClassifier(),xgboost_params),\n",
    "\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=1000; total time=   2.7s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=15, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=15, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=15, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=15, n_estimators=1000; total time=   3.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=15, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=15, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=8, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=8, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=8, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=200; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=20, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=20, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=20, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=1000; total time=   2.9s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=1000; total time=   3.0s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=15, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=15, n_estimators=1000; total time=   1.6s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=15, n_estimators=1000; total time=   1.5s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=8, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=8, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=8, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=8, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=1000; total time=   1.7s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=15, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=2, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=15, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=15, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=15, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=1000; total time=   3.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=1000; total time=   3.2s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=1000; total time=   2.8s\n",
      "[CV] END max_depth=None, max_features=7, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=7, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=7, min_samples_split=20, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.4s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.7s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=15, n_estimators=1000; total time=   2.7s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=15, n_estimators=1000; total time=   2.6s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=15, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.7s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.3s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=20, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=20, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=1000; total time=   1.7s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=1000; total time=   1.6s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=200; total time=   0.5s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=200; total time=   0.6s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=8, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=5, max_features=7, min_samples_split=15, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=8, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=1000; total time=   2.7s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=1000; total time=   3.0s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=2, n_estimators=1000; total time=   2.8s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.3s\n",
      "[CV] END max_depth=None, max_features=8, min_samples_split=2, n_estimators=500; total time=   1.5s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=20, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=2, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=None, max_features=auto, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=20, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=20, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=20, n_estimators=1000; total time=   2.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=1000; total time=   1.9s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=8, n_estimators=1000; total time=   1.8s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=15, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=15, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=None, max_features=5, min_samples_split=15, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=auto, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=8, n_estimators=1000; total time=   2.0s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=8, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=8, n_estimators=1000; total time=   2.1s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=8, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=5, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.4s\n",
      "[CV] END max_depth=8, max_features=8, min_samples_split=2, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=8, max_features=auto, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=5, max_features=auto, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=20, n_estimators=500; total time=   0.9s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=5, min_samples_split=20, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=500; total time=   0.8s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=15, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=500; total time=   2.0s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=8, n_estimators=500; total time=   1.2s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=10, max_features=auto, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=8, n_estimators=1000; total time=   2.5s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=8, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=15, max_features=7, min_samples_split=8, n_estimators=1000; total time=   2.4s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=5, max_features=8, min_samples_split=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=8, max_features=7, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=15, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=15, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=5, max_features=5, min_samples_split=15, n_estimators=500; total time=   0.7s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=15, max_features=5, min_samples_split=2, n_estimators=100; total time=   0.1s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=7, min_samples_split=20, n_estimators=500; total time=   1.0s\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=60; total time=   0.0s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=60; total time=   0.0s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=60; total time=   0.0s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=70; total time=   0.0s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=70; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=70; total time=   0.0s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=80; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=80; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=80; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=90; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=90; total time=   0.1s\n",
      "[CV] END ...................algorithm=SAMME, n_estimators=90; total time=   0.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=50; total time=   0.0s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=50; total time=   0.0s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=50; total time=   0.0s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=60; total time=   0.0s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=60; total time=   0.0s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=60; total time=   0.0s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=70; total time=   0.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=70; total time=   0.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=70; total time=   0.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=80; total time=   0.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=80; total time=   0.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=80; total time=   0.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=90; total time=   0.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=90; total time=   0.1s\n",
      "[CV] END .................algorithm=SAMME.R, n_estimators=90; total time=   0.1s\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, min_samples_split=15, n_estimators=1000; total time=   5.9s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, min_samples_split=15, n_estimators=1000; total time=   5.8s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, min_samples_split=15, n_estimators=1000; total time=   6.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, min_samples_split=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, min_samples_split=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, min_samples_split=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=500; total time=   5.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=500; total time=   5.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=500; total time=   5.4s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=200; total time=   5.6s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=200; total time=   5.8s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=200; total time=   6.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, min_samples_split=2, n_estimators=1000; total time=   4.9s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, min_samples_split=2, n_estimators=1000; total time=   4.9s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, min_samples_split=2, n_estimators=1000; total time=   4.7s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=200; total time=   3.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=200; total time=   3.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=200; total time=   3.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=1000; total time=   5.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=1000; total time=   5.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=1000; total time=   5.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=1000; total time=   5.7s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=1000; total time=   5.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=1000; total time=   5.7s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=2, n_estimators=200; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=2, n_estimators=200; total time=   3.8s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=2, n_estimators=200; total time=   4.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=200; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=200; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=200; total time=   2.3s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=15, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=15, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=15, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=8, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=8, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=8, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=200; total time=   6.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=200; total time=   7.6s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=200; total time=   6.7s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=1000; total time=   8.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=1000; total time=   8.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=1000; total time=   7.9s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=20, n_estimators=200; total time=   5.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=20, n_estimators=200; total time=   6.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=20, n_estimators=200; total time=   6.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=200; total time=   3.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=200; total time=   2.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=200; total time=   2.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=15, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=15, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=15, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=500; total time=   6.8s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=500; total time=   5.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=500; total time=   6.1s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=200; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=200; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=200; total time=   1.8s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=1000; total time=   5.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=1000; total time=   5.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=1000; total time=   5.5s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=15, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=1000; total time=   6.0s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=1000; total time=   6.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=1000; total time=   6.3s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=None, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=8, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=8, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=8, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=15, n_estimators=1000; total time=   6.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=15, n_estimators=1000; total time=   6.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=15, n_estimators=1000; total time=   7.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=15, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=500; total time=   5.2s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=500; total time=   5.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=8, n_estimators=500; total time=   6.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, min_samples_split=2, n_estimators=1000; total time=   9.8s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, min_samples_split=2, n_estimators=1000; total time=   9.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=8, min_samples_split=2, n_estimators=1000; total time=  10.3s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=15, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, min_samples_split=8, n_estimators=500; total time=   6.8s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, min_samples_split=8, n_estimators=500; total time=   6.7s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, min_samples_split=8, n_estimators=500; total time=   6.7s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=100; total time=   3.0s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=100; total time=   3.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, min_samples_split=8, n_estimators=200; total time=   2.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, min_samples_split=8, n_estimators=200; total time=   2.4s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=8, min_samples_split=8, n_estimators=200; total time=   2.1s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=500; total time=   7.3s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=500; total time=   8.7s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=500; total time=   7.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=200; total time=   7.1s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=200; total time=   6.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=200; total time=   7.7s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=None, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=None, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=None, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=200; total time=   2.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=200; total time=   2.7s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=200; total time=   2.7s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=10, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=10, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=10, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=500; total time=   6.8s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=500; total time=   6.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=None, min_samples_split=8, n_estimators=500; total time=   7.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=200; total time=   4.5s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=200; total time=   5.6s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=200; total time=   5.1s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=500; total time=   7.6s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=500; total time=   9.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=15, n_estimators=500; total time=  12.8s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=8, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=5, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=5, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=5, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, min_samples_split=2, n_estimators=500; total time=  12.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, min_samples_split=2, n_estimators=500; total time=  11.5s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=10, min_samples_split=2, n_estimators=500; total time=   9.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, min_samples_split=2, n_estimators=1000; total time=   5.6s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, min_samples_split=2, n_estimators=1000; total time=   6.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=None, min_samples_split=2, n_estimators=1000; total time=   7.2s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=None, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=20, n_estimators=500; total time=   8.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=20, n_estimators=500; total time=   8.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=20, n_estimators=500; total time=   7.5s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=1000; total time=   8.5s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=1000; total time=  10.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=1000; total time=   9.3s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=10, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=10, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=10, min_samples_split=8, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=1000; total time=  10.1s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=1000; total time=  10.4s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, min_samples_split=15, n_estimators=1000; total time=  11.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, min_samples_split=15, n_estimators=200; total time=   3.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, min_samples_split=15, n_estimators=200; total time=   2.8s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=8, min_samples_split=15, n_estimators=200; total time=   3.3s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=10, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=10, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=10, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=1000; total time=   9.4s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=1000; total time=   9.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=1000; total time=   9.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, min_samples_split=8, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, min_samples_split=8, n_estimators=100; total time=   3.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=10, min_samples_split=8, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=200; total time=   1.8s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=200; total time=   1.7s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=5, min_samples_split=20, n_estimators=200; total time=   1.9s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, min_samples_split=8, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=15, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, min_samples_split=20, n_estimators=200; total time=   6.9s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, min_samples_split=20, n_estimators=200; total time=   6.8s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, min_samples_split=20, n_estimators=200; total time=   5.7s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=None, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=None, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=None, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=None, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=8, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.6s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.4s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=15, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=15, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=15, min_samples_split=20, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=15, n_estimators=500; total time=   8.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=15, n_estimators=500; total time=   8.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=8, min_samples_split=15, n_estimators=500; total time=   7.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, min_samples_split=8, n_estimators=200; total time=   5.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, min_samples_split=8, n_estimators=200; total time=   6.0s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=10, min_samples_split=8, n_estimators=200; total time=   5.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=15, min_samples_split=8, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=1000; total time=  12.3s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=1000; total time=  11.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=None, min_samples_split=15, n_estimators=1000; total time=  12.3s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=8, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=10, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=10, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=10, min_samples_split=15, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=10, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=10, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=deviance, max_depth=10, min_samples_split=15, n_estimators=500; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=10, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=10, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=exponential, max_depth=10, min_samples_split=20, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=None, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=None, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=None, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=5, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=5, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=5, min_samples_split=20, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=100; total time=   2.8s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=100; total time=   2.7s\n",
      "[CV] END criterion=squared_error, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=100; total time=   2.7s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=None, min_samples_split=15, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=deviance, max_depth=5, min_samples_split=8, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=None, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=None, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=None, min_samples_split=2, n_estimators=1000; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=1000; total time=  12.2s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=1000; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, loss=log_loss, max_depth=15, min_samples_split=8, n_estimators=1000; total time=  11.3s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.8s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.8s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=5, min_samples_split=8, n_estimators=200; total time=   1.9s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=log_loss, max_depth=10, min_samples_split=20, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=mse, loss=deviance, max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.0s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=1000; total time=  11.1s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=1000; total time=   9.6s\n",
      "[CV] END criterion=friedman_mse, loss=exponential, max_depth=15, min_samples_split=20, n_estimators=1000; total time=   9.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=20, n_estimators=500; total time=  10.2s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=20, n_estimators=500; total time=  10.8s\n",
      "[CV] END criterion=squared_error, loss=log_loss, max_depth=15, min_samples_split=20, n_estimators=500; total time=   9.8s\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=15, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=15, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=15, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=300; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=None, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=10, n_estimators=300; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=10, n_estimators=300; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=10, n_estimators=300; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   1.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   0.7s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, n_estimators=200; total time=   0.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, n_estimators=200; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=15, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=15, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=15, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=8, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=10, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=10, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=10, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=None, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=15, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, n_estimators=300; total time=   0.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, n_estimators=300; total time=   0.6s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=10, n_estimators=300; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.01, max_depth=10, n_estimators=200; total time=   0.3s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=None, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=None, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=None, n_estimators=100; total time=   0.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=None, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.1, max_depth=10, n_estimators=300; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=None, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.4, learning_rate=0.1, max_depth=15, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=None, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.01, max_depth=5, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.5s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   0.9s\n",
      "[CV] END colsample_bytree=1, learning_rate=0.01, max_depth=15, n_estimators=300; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=10, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=200; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=100; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.3, learning_rate=0.1, max_depth=8, n_estimators=300; total time=   0.4s\n",
      "For RF\n",
      "{'n_estimators': 500, 'min_samples_split': 2, 'max_features': 8, 'max_depth': 15}\n",
      "For AdaBoostClassifier\n",
      "{'n_estimators': 90, 'algorithm': 'SAMME.R'}\n",
      "For GradientBoostClassifier\n",
      "{'n_estimators': 200, 'min_samples_split': 15, 'max_depth': None, 'loss': 'exponential', 'criterion': 'squared_error'}\n",
      "For XgBoostClassifier\n",
      "{'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "model_param = {}\n",
    "tuned_model = {}\n",
    "\n",
    "for name, model, params in random_cv_models:\n",
    "    randomcv = RandomizedSearchCV(estimator=model,param_distributions=params,n_iter=100,cv=3,verbose=2,refit=True) \n",
    "    tuned_model[name] = randomcv\n",
    "    randomcv.fit(X_train,y_train)\n",
    "    model_param[name] = randomcv.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"For {model_name}\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunned Model Performance: \n",
      "\n",
      "Model: XgBoost Classifier\n",
      "Model Performance for Training set\n",
      "- Accuracy: 0.9988\n",
      "- F1-Score: 0.9966\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9933\n",
      "- Roc Auc Score: 0.9967\n",
      "\n",
      "Model Performance for Test set\n",
      "- Accuracy: 0.9201\n",
      "- F1-Score: 0.7598\n",
      "- Precision: 0.9444\n",
      "- Recall: 0.6355\n",
      "- Roc Auc Score: 0.8131\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Model: XgBoost Classifier\n",
      "Model Performance for Training set\n",
      "- Accuracy: 0.8595\n",
      "- F1-Score: 0.4664\n",
      "- Precision: 0.7643\n",
      "- Recall: 0.3356\n",
      "- Roc Auc Score: 0.6562\n",
      "\n",
      "Model Performance for Test set\n",
      "- Accuracy: 0.8432\n",
      "- F1-Score: 0.4464\n",
      "- Precision: 0.7500\n",
      "- Recall: 0.3178\n",
      "- Roc Auc Score: 0.6457\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Model: XgBoost Classifier\n",
      "Model Performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1-Score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "\n",
      "Model Performance for Test set\n",
      "- Accuracy: 0.9387\n",
      "- F1-Score: 0.8302\n",
      "- Precision: 0.9237\n",
      "- Recall: 0.7539\n",
      "- Roc Auc Score: 0.8692\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "Model: XgBoost Classifier\n",
      "Model Performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1-Score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "\n",
      "Model Performance for Test set\n",
      "- Accuracy: 0.9337\n",
      "- F1-Score: 0.8113\n",
      "- Precision: 0.9350\n",
      "- Recall: 0.7165\n",
      "- Roc Auc Score: 0.8521\n",
      "-----------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Tunned Model Performance: \\n\")\n",
    "\n",
    "for name,tuned_model in tuned_model.items():\n",
    "\n",
    "    y_test_pred = tuned_model.predict(X_test)\n",
    "    y_train_pred = tuned_model.predict(X_train)\n",
    "\n",
    "    # Trained Data performance \n",
    "    model_train_acc = accuracy_score(y_train,y_train_pred)\n",
    "    model_train_f1 = f1_score(y_train,y_train_pred)\n",
    "    model_train_precision = precision_score(y_train,y_train_pred)\n",
    "    model_train_recall = recall_score(y_train,y_train_pred)\n",
    "    model_train_rocauc_score = roc_auc_score(y_train,y_train_pred)\n",
    "\n",
    "    # Test Data performance \n",
    "    model_test_acc = accuracy_score(y_test,y_test_pred)\n",
    "    model_test_f1 = f1_score(y_test,y_test_pred)\n",
    "    model_test_precision = precision_score(y_test,y_test_pred)\n",
    "    model_test_recall = recall_score(y_test,y_test_pred)\n",
    "    model_test_rocauc_score = roc_auc_score(y_test,y_test_pred)\n",
    "\n",
    "    print(f\"Model: {key}\")\n",
    "\n",
    "    print(\"Model Performance for Training set\")\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_train_acc))\n",
    "    print(\"- F1-Score: {:.4f}\".format(model_train_f1))\n",
    "    print(\"- Precision: {:.4f}\".format(model_train_precision))\n",
    "    print(\"- Recall: {:.4f}\".format(model_train_recall))\n",
    "    print(\"- Roc Auc Score: {:.4f}\".format(model_train_rocauc_score))\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Model Performance for Test set\")\n",
    "    print(\"- Accuracy: {:.4f}\".format(model_test_acc))\n",
    "    print(\"- F1-Score: {:.4f}\".format(model_test_f1))\n",
    "    print(\"- Precision: {:.4f}\".format(model_test_precision))\n",
    "    print(\"- Recall: {:.4f}\".format(model_test_recall))\n",
    "    print(\"- Roc Auc Score: {:.4f}\".format(model_test_rocauc_score))\n",
    "\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2942d51fb30>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "auc_models = [\n",
    "    {\n",
    "        'label': 'Adaboost Classifier',\n",
    "        'model': AdaBoostClassifier(n_estimators=model_param['AdaBoostClassifier']['n_estimators'],algorithm=model_param['AdaBoostClassifier']['algorithm']),\n",
    "        'auc': 0.6457\n",
    "    },\n",
    "    {\n",
    "        'label': 'Random Forest Classifier',\n",
    "        'model': RandomForestClassifier(n_estimators=model_param['RF']['n_estimators'],min_samples_split=model_param['RF']['min_samples_split'],max_features=model_param['RF']['max_features']),\n",
    "        'auc': 0.8256\n",
    "    },\n",
    "    {\n",
    "        'label': 'Gradient Boost Classifier',\n",
    "        'model': GradientBoostingClassifier(n_estimators=model_param['GradientBoostClassifier']['n_estimators'],min_samples_split=model_param['GradientBoostClassifier']['min_samples_split'],max_depth=model_param['GradientBoostClassifier']['max_depth'],loss=model_param['GradientBoostClassifier']['loss'],criterion=model_param['GradientBoostClassifier']['criterion']),\n",
    "        'auc': 0.875\n",
    "    },\n",
    "    {\n",
    "        'label': 'Xg Boost Classifier',\n",
    "        'model': XGBClassifier(n_estimators=model_param['XgBoostClassifier']['n_estimators'],max_depth=model_param['XgBoostClassifier']['max_depth'],colsample_bytree=model_param['XgBoostClassifier']['colsample_bytree'],learning_rate=model_param['XgBoostClassifier']['learning_rate']),\n",
    "        'auc': 0.875\n",
    "    },\n",
    "    \n",
    "]\n",
    "\n",
    "# create loop through all model \n",
    "for algo in auc_models:\n",
    "    model = algo['model']\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    # compute false positive rate, true positive rate\n",
    "    fpr, tpr, threshold = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "\n",
    "    # calculate area under curve to display on plot\n",
    "    plt.plot(fpr ,tpr , label='%s ROC (area = %0.2f)' % (algo['label'],algo['auc']))\n",
    "\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.xlabel('False Positive Rate [1-Specificity]')\n",
    "plt.ylabel('True Positive Rate [Sensitivity]')\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
