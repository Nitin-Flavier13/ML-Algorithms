{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_name</th>\n",
       "      <th>vehicle_age</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "      <th>selling_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>120000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>19.70</td>\n",
       "      <td>796</td>\n",
       "      <td>46.30</td>\n",
       "      <td>5</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hyundai Grand</td>\n",
       "      <td>5</td>\n",
       "      <td>20000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1197</td>\n",
       "      <td>82.00</td>\n",
       "      <td>5</td>\n",
       "      <td>550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyundai i20</td>\n",
       "      <td>11</td>\n",
       "      <td>60000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1197</td>\n",
       "      <td>80.00</td>\n",
       "      <td>5</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maruti Alto</td>\n",
       "      <td>9</td>\n",
       "      <td>37000</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>20.92</td>\n",
       "      <td>998</td>\n",
       "      <td>67.10</td>\n",
       "      <td>5</td>\n",
       "      <td>226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ford Ecosport</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Manual</td>\n",
       "      <td>22.77</td>\n",
       "      <td>1498</td>\n",
       "      <td>98.59</td>\n",
       "      <td>5</td>\n",
       "      <td>570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        car_name  vehicle_age  km_driven seller_type fuel_type  \\\n",
       "0    Maruti Alto            9     120000  Individual    Petrol   \n",
       "1  Hyundai Grand            5      20000  Individual    Petrol   \n",
       "2    Hyundai i20           11      60000  Individual    Petrol   \n",
       "3    Maruti Alto            9      37000  Individual    Petrol   \n",
       "4  Ford Ecosport            6      30000      Dealer    Diesel   \n",
       "\n",
       "  transmission_type  mileage  engine  max_power  seats  selling_price  \n",
       "0            Manual    19.70     796      46.30      5         120000  \n",
       "1            Manual    18.90    1197      82.00      5         550000  \n",
       "2            Manual    17.00    1197      80.00      5         215000  \n",
       "3            Manual    20.92     998      67.10      5         226000  \n",
       "4            Manual    22.77    1498      98.59      5         570000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Nitin Flavier\\Desktop\\Data Nexus\\Data Science\\ML_BootCamp\\ML_Algos\\Boosting\\Dataset\\updated_used_car_price.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        car_name  vehicle_age  km_driven seller_type fuel_type  \\\n",
      "0    Maruti Alto            9     120000  Individual    Petrol   \n",
      "1  Hyundai Grand            5      20000  Individual    Petrol   \n",
      "2    Hyundai i20           11      60000  Individual    Petrol   \n",
      "3    Maruti Alto            9      37000  Individual    Petrol   \n",
      "4  Ford Ecosport            6      30000      Dealer    Diesel   \n",
      "\n",
      "  transmission_type  mileage  engine  max_power  seats  \n",
      "0            Manual    19.70     796      46.30      5  \n",
      "1            Manual    18.90    1197      82.00      5  \n",
      "2            Manual    17.00    1197      80.00      5  \n",
      "3            Manual    20.92     998      67.10      5  \n",
      "4            Manual    22.77    1498      98.59      5  \n",
      "0    120000\n",
      "1    550000\n",
      "2    215000\n",
      "3    226000\n",
      "4    570000\n",
      "Name: selling_price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df.drop('selling_price',axis=1)\n",
    "y = df['selling_price']\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Encoding\n",
    "\n",
    "We will do label encoding, \n",
    "\n",
    "Ordinal Misrepresentation:      \n",
    "If the categorical values are not ordinal (no natural order), the numerical assignment might imply a relationship between categories that doesn't exist.  \n",
    "Example: Encoding [\"Dog\" -> 0, \"Cat\" -> 1, \"Rabbit\" -> 2] implies an ordering, which is incorrect.   \n",
    "\n",
    "In our case we want a relation between the feature 'model' with selling price which is ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "X['car_name'] = le.fit_transform(X['car_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "car_name\n",
       "40     906\n",
       "77     890\n",
       "76     781\n",
       "65     778\n",
       "27     757\n",
       "      ... \n",
       "83       1\n",
       "103      1\n",
       "17       1\n",
       "31       1\n",
       "18       1\n",
       "Name: count, Length: 121, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['car_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter drop='first' in OneHotEncoder is used to handle the issue of multicollinearity that arises when all categories of a categorical variable are encoded into binary columns.\n",
    "\n",
    "Including all n binary columns can introduce multicollinearity (a situation where one column can be perfectly predicted by the others) when used in linear models. Dropping one category prevents this issue while retaining the necessary information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns \n",
    "onehot_columns = ['seller_type','fuel_type','transmission_type'] \n",
    "\n",
    "num_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\",oh_transformer,onehot_columns),\n",
    "        (\"StandardScaler\",num_transformer,num_features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso \n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true_value,pred_value):\n",
    "    mae = mean_absolute_error(true_value,pred_value)\n",
    "    mse = mean_squared_error(true_value,pred_value)\n",
    "    r2_square = r2_score(true_value,pred_value)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return mae,rmse,r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Lasso\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 563785.4152\n",
      " - Mean Absolute Error: 563785.4152\n",
      " - R2_Score: 0.6167\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 502836.1750\n",
      " - Mean Absolute Error: 502836.1750\n",
      " - R2_Score: 0.6577\n",
      "\n",
      "Model:  Ridge\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 563786.2859\n",
      " - Mean Absolute Error: 563786.2859\n",
      " - R2_Score: 0.6167\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 502820.1247\n",
      " - Mean Absolute Error: 502820.1247\n",
      " - R2_Score: 0.6577\n",
      "\n",
      "Model:  Linear Regression\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 563785.4054\n",
      " - Mean Absolute Error: 563785.4054\n",
      " - R2_Score: 0.6167\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 502836.9470\n",
      " - Mean Absolute Error: 502836.9470\n",
      " - R2_Score: 0.6577\n",
      "\n",
      "Model:  K-Neighbours Regressor\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 351502.5056\n",
      " - Mean Absolute Error: 351502.5056\n",
      " - R2_Score: 0.8510\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 290729.6542\n",
      " - Mean Absolute Error: 290729.6542\n",
      " - R2_Score: 0.8856\n",
      "\n",
      "Model:  Decision Tree\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 19837.9410\n",
      " - Mean Absolute Error: 19837.9410\n",
      " - R2_Score: 0.9995\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 363967.1073\n",
      " - Mean Absolute Error: 363967.1073\n",
      " - R2_Score: 0.8207\n",
      "\n",
      "Model:  Random Forest Regressor\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 139677.4533\n",
      " - Mean Absolute Error: 139677.4533\n",
      " - R2_Score: 0.9765\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 236407.2029\n",
      " - Mean Absolute Error: 236407.2029\n",
      " - R2_Score: 0.9243\n",
      "\n",
      "Model:  AdaBoost Regressor\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 465868.2944\n",
      " - Mean Absolute Error: 465868.2944\n",
      " - R2_Score: 0.7383\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 521786.1293\n",
      " - Mean Absolute Error: 521786.1293\n",
      " - R2_Score: 0.6314\n",
      "\n",
      "Model:  Gradient Regressor\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 193908.3522\n",
      " - Mean Absolute Error: 193908.3522\n",
      " - R2_Score: 0.9547\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 262769.0360\n",
      " - Mean Absolute Error: 262769.0360\n",
      " - R2_Score: 0.9065\n",
      "\n",
      "Model:  XgBoost Regressor\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 83315.1625\n",
      " - Mean Absolute Error: 83315.1625\n",
      " - R2_Score: 0.9916\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 330168.1494\n",
      " - Mean Absolute Error: 330168.1494\n",
      " - R2_Score: 0.8524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Begin Model training \n",
    "models = {\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"K-Neighbours Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    'AdaBoost Regressor': AdaBoostRegressor(),\n",
    "    'Gradient Regressor': GradientBoostingRegressor(),\n",
    "    'XgBoost Regressor': XGBRegressor()\n",
    "}\n",
    "\n",
    "for key,value in models.items():\n",
    "    model = value \n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    # evaluate the model \n",
    "    mae_test, rmse_test, r2_test = evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "    mae_train, rmse_train, r2_train = evaluate_model(y_train,y_train_pred) \n",
    "\n",
    "    print(\"Model: \",key)\n",
    "\n",
    "    print(\" Model Performance on Training Set: \")\n",
    "    print(\" - Root Mean Square Error: {:.4f}\".format(rmse_train))\n",
    "    print(\" - Mean Absolute Error: {:.4f}\".format(rmse_train))\n",
    "    print(\" - R2_Score: {:.4f}\".format(r2_train))\n",
    "    print()\n",
    "    print(\" Model Performance on Test Set: \")\n",
    "    print(\" - Root Mean Square Error: {:.4f}\".format(rmse_test))\n",
    "    print(\" - Mean Absolute Error: {:.4f}\".format(rmse_test))\n",
    "    print(\" - R2_Score: {:.4f}\".format(r2_test))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameter-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we will take KNN and Random-Forest Regressor \n",
    "\n",
    "knn_params = {\"n_neighbors\": [2,3,10,20,40,50]}\n",
    "\n",
    "rf_params = {\n",
    "    \"max_depth\": [5,8,15,10,None],\n",
    "    \"max_features\": [5,7,8,\"auto\"],\n",
    "    \"min_samples_split\": [2,8,15,20],\n",
    "    \"n_estimators\": [100,200,500,1000]\n",
    "}\n",
    "\n",
    "ada_params = {\n",
    "    \"n_estimators\": [50,55,60,65,70,80],\n",
    "    \"loss\": ['linear','square','exponential']\n",
    "}\n",
    "\n",
    "gradientboost_params = {\n",
    "    \"loss\": ['squared_error','huber','absolute_error'],\n",
    "    \"criterion\": ['friedman_mse','squared_error','mse'],\n",
    "    \"min_samples_split\": [2,8,15,20],\n",
    "    \"n_estimators\": [100,200,500,1000],\n",
    "    \"max_depth\": [5,8,15,None,10],\n",
    "    \"learning_rate\": [0.1,0.01,0.02,0.2]\n",
    "}\n",
    "\n",
    "xgboost_params = {\n",
    "    \"learning_rate\": [0.1,0.01],\n",
    "    \"max_depth\": [5,8,15,None,10],\n",
    "    \"n_estimators\": [100,200,300],\n",
    "    \"colsample_bytree\": [0.5,0.8,1,0.3,0.4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunning_models = [\n",
    "    ('KNN',KNeighborsRegressor(),knn_params),\n",
    "    ('Random Forest', RandomForestRegressor(),rf_params),\n",
    "    ('AdaBoost Regression',AdaBoostRegressor(),ada_params),\n",
    "    ('GradientBoost Regression',GradientBoostingRegressor(),gradientboost_params),\n",
    "    ('XgBoost Regression',XGBRegressor(),xgboost_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "{'KNN': {'n_neighbors': 2}, 'Random Forest': {'n_estimators': 500, 'min_samples_split': 2, 'max_features': 5, 'max_depth': 15}, 'AdaBoost Regression': {'n_estimators': 80, 'loss': 'linear'}, 'GradientBoost Regression': {'n_estimators': 500, 'min_samples_split': 8, 'max_depth': 5, 'loss': 'squared_error', 'learning_rate': 0.2, 'criterion': 'friedman_mse'}, 'XgBoost Regression': {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.1, 'colsample_bytree': 0.5}}\n",
      "\n",
      "For the model KNN\n",
      "n_neighbors 2  \n",
      "\n",
      "For the model Random Forest\n",
      "n_estimators 500  min_samples_split 2  max_features 5  max_depth 15  \n",
      "\n",
      "For the model AdaBoost Regression\n",
      "n_estimators 80  loss linear  \n",
      "\n",
      "For the model GradientBoost Regression\n",
      "n_estimators 500  min_samples_split 8  max_depth 5  loss squared_error  learning_rate 0.2  criterion friedman_mse  \n",
      "\n",
      "For the model XgBoost Regression\n",
      "n_estimators 200  max_depth 8  learning_rate 0.1  colsample_bytree 0.5  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "model_param = {}\n",
    "best_tuned_model = {}\n",
    "\n",
    "for name,model,params in tunning_models:\n",
    "    randomcv = RandomizedSearchCV(estimator=model,param_distributions=params,cv=3,verbose=1,refit=True)\n",
    "    randomcv.fit(X_train,y_train)\n",
    "    best_tuned_model[name] = randomcv\n",
    "    model_param[name] = randomcv.best_params_\n",
    "\n",
    "print(model_param)\n",
    "print()\n",
    "for key1,dict in model_param.items():\n",
    "    print(f\"For the model {key1}\")\n",
    "    for k,v in dict.items():\n",
    "        print(k,v, end=\"  \")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunned Model Performance: \n",
      "\n",
      "Model:  XgBoost Regressor\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 219323.1679\n",
      " - Mean Absolute Error: 219323.1679\n",
      " - R2_Score: 0.9420\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 280835.6928\n",
      " - Mean Absolute Error: 280835.6928\n",
      " - R2_Score: 0.8932\n",
      "\n",
      "Model:  XgBoost Regressor\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 145696.1810\n",
      " - Mean Absolute Error: 145696.1810\n",
      " - R2_Score: 0.9744\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 218173.7932\n",
      " - Mean Absolute Error: 218173.7932\n",
      " - R2_Score: 0.9356\n",
      "\n",
      "Model:  XgBoost Regressor\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 386271.9220\n",
      " - Mean Absolute Error: 386271.9220\n",
      " - R2_Score: 0.8201\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 436891.4754\n",
      " - Mean Absolute Error: 436891.4754\n",
      " - R2_Score: 0.7416\n",
      "\n",
      "Model:  XgBoost Regressor\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 66411.8358\n",
      " - Mean Absolute Error: 66411.8358\n",
      " - R2_Score: 0.9947\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 223176.0640\n",
      " - Mean Absolute Error: 223176.0640\n",
      " - R2_Score: 0.9326\n",
      "\n",
      "Model:  XgBoost Regressor\n",
      " Model Performance on Training Set: \n",
      " - Root Mean Square Error: 76864.3052\n",
      " - Mean Absolute Error: 76864.3052\n",
      " - R2_Score: 0.9929\n",
      "\n",
      " Model Performance on Test Set: \n",
      " - Root Mean Square Error: 296449.7512\n",
      " - Mean Absolute Error: 296449.7512\n",
      " - R2_Score: 0.8810\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tunned Model Performance: \\n\")\n",
    "\n",
    "for name,tuned_model in best_tuned_model.items():\n",
    "\n",
    "    y_test_pred = tuned_model.predict(X_test)\n",
    "    y_train_pred = tuned_model.predict(X_train)\n",
    "\n",
    "    # evaluate the model \n",
    "    mae_test, rmse_test, r2_test = evaluate_model(y_test,y_test_pred)\n",
    "\n",
    "    mae_train, rmse_train, r2_train = evaluate_model(y_train,y_train_pred) \n",
    "\n",
    "    print(\"Model: \",key)\n",
    "\n",
    "    print(\" Model Performance on Training Set: \")\n",
    "    print(\" - Root Mean Square Error: {:.4f}\".format(rmse_train))\n",
    "    print(\" - Mean Absolute Error: {:.4f}\".format(rmse_train))\n",
    "    print(\" - R2_Score: {:.4f}\".format(r2_train))\n",
    "    print()\n",
    "    print(\" Model Performance on Test Set: \")\n",
    "    print(\" - Root Mean Square Error: {:.4f}\".format(rmse_test))\n",
    "    print(\" - Mean Absolute Error: {:.4f}\".format(rmse_test))\n",
    "    print(\" - R2_Score: {:.4f}\".format(r2_test))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
